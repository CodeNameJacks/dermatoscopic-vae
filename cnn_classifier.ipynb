{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "373fbba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "092d5d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "889780b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAE architecture and paramteres\n",
    "kernels = 2\n",
    "strides = 2\n",
    "latent_dim = 28\n",
    "filters = [32, 64, 128, 224, 512]\n",
    "input_shape = (224, 224, 3)\n",
    "last_conv_dim = int(input_shape[0] / (2 ** len(filters)))\n",
    "b_norm = 3\n",
    "#Batch Norm\n",
    "epsilon = 1e-5\n",
    "#spatial Classifier\n",
    "num_classes = 4\n",
    "#dataset\n",
    "ham_dataset_dir = 'ham_minified'\n",
    "batch_size = 48\n",
    "seed = 42\n",
    "#define early stopping paramter\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e2f637f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_dataset_dir = 'ham_minified'\n",
    "nv_source_dir = 'nv_src'\n",
    "nv_test_num = 200\n",
    "nv_gen_num = 0\n",
    "batch_size = 48\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "941ac64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = list(os.walk(ham_dataset_dir + '/nv'))[0][2]\n",
    "for image_to_delete in images:\n",
    "    path = Path(f'{ham_dataset_dir}/nv/{image_to_delete}')\n",
    "    path.unlink(missing_ok=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "55f324d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = list(os.walk(nv_source_dir + '/nv_true'))[0][2]\n",
    "nv_images = random.sample(images, nv_test_num)\n",
    "for true_image in nv_images:\n",
    "    shutil.copy(nv_source_dir + '/nv_true/' + true_image, ham_dataset_dir + '/nv/' + true_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dc338aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = list(os.walk(nv_source_dir + '/gen_data'))[0][2]\n",
    "gen_images = random.sample(images, nv_gen_num)\n",
    "for gen_image in gen_images:\n",
    "    shutil.copy(nv_source_dir + '/gen_data/' + gen_image, ham_dataset_dir + '/nv/' + gen_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f4992957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2926 files belonging to 4 classes.\n",
      "Using 877 files for validation.\n",
      "Found 2926 files belonging to 4 classes.\n",
      "Using 877 files for validation.\n"
     ]
    }
   ],
   "source": [
    "#load and split datatse\n",
    "train_ds = keras.preprocessing.image_dataset_from_directory(ham_dataset_dir, validation_split=0.3, color_mode='rgb',\n",
    "                                                          labels='inferred', shuffle=True, subset='validation', image_size=(224, 224),\n",
    "                                                          batch_size=batch_size, seed=seed)\n",
    "\n",
    "val_ds = keras.preprocessing.image_dataset_from_directory(ham_dataset_dir, validation_split=0.3, color_mode='rgb',\n",
    "                                                          labels='inferred', shuffle=True, subset='validation', image_size=(224, 224),\n",
    "                                                          batch_size=batch_size, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "978b6e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2926 files belonging to 4 classes.\n",
      "Using 2049 files for training.\n"
     ]
    }
   ],
   "source": [
    "classes = train_ds.class_names\n",
    "train_ds_single_batch = keras.preprocessing.image_dataset_from_directory(ham_dataset_dir, validation_split=0.3, color_mode='rgb',\n",
    "                                                     labels='inferred', shuffle=True, subset='training', image_size=(224, 224),\n",
    "                                                     batch_size=1, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8450b3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.40728022 0.66439689 0.65926641 3.73905109]\n"
     ]
    }
   ],
   "source": [
    "y = np.array([label.numpy()[0] for _, label in train_ds_single_batch])\n",
    "class_weights_list = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "print(class_weights_list)\n",
    "class_weights = {}\n",
    "\n",
    "for i in range(len(class_weights_list)):\n",
    "    class_weights[i] = class_weights_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "93f28f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batches = tf.data.experimental.cardinality(val_ds)\n",
    "test_ds = val_ds.take(val_batches // 2)\n",
    "val_ds = val_ds.skip(val_batches // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c0caa454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of validation batches: 10\n",
      "Number of test batches: 9\n"
     ]
    }
   ],
   "source": [
    "print('Number of validation batches: %d' % tf.data.experimental.cardinality(val_ds))\n",
    "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "583fbf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale immages\n",
    "rescale = keras.layers.experimental.preprocessing.Rescaling(scale=1.0 / 255)\n",
    "train_ds = train_ds.map(lambda x, y: (rescale(x), y))\n",
    "val_ds = val_ds.map(lambda x, y: (rescale(x), y))\n",
    "test_ds = test_ds.map(lambda x, y: (rescale(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0c64b846",
   "metadata": {},
   "outputs": [],
   "source": [
    "#autotune dataset\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "94eb952c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 112, 112, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 112, 112, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 56, 56, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 56, 56, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 56, 56, 64)        0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 28, 28, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 14, 14, 224)       258272    \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 14, 14, 224)      896       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 14, 14, 224)       0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 7, 7, 512)         1032704   \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 7, 7, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                1605696   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,994,020\n",
      "Trainable params: 2,992,100\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#define the neural network\n",
    "model = Sequential()\n",
    "for conv_filter in filters:\n",
    "    model.add(keras.layers.Conv2D(conv_filter, 3, strides=2, padding='same', input_shape=input_shape))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-5), activation='relu'))\n",
    "model.add(keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#print summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d2a107dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimize the model with using Adam\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6076fa78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19/19 [==============================] - 2s 85ms/step - loss: 3.9372 - accuracy: 0.3615 - val_loss: 1.5902 - val_accuracy: 0.0854\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 2s 77ms/step - loss: 1.3994 - accuracy: 0.3979 - val_loss: 1.6370 - val_accuracy: 0.1978\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 1.2323 - accuracy: 0.4550 - val_loss: 1.6989 - val_accuracy: 0.1843\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 2s 77ms/step - loss: 1.1234 - accuracy: 0.5108 - val_loss: 1.9070 - val_accuracy: 0.1506\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 2s 76ms/step - loss: 1.1077 - accuracy: 0.5211 - val_loss: 2.2344 - val_accuracy: 0.1528\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 2s 78ms/step - loss: 0.9596 - accuracy: 0.5895 - val_loss: 2.3043 - val_accuracy: 0.1528\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 2s 78ms/step - loss: 0.9724 - accuracy: 0.5690 - val_loss: 1.8617 - val_accuracy: 0.2000\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 2s 77ms/step - loss: 0.9262 - accuracy: 0.6214 - val_loss: 2.3186 - val_accuracy: 0.1596\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 2s 78ms/step - loss: 0.9426 - accuracy: 0.6043 - val_loss: 1.7448 - val_accuracy: 0.3843\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 2s 79ms/step - loss: 0.9199 - accuracy: 0.6363 - val_loss: 2.1665 - val_accuracy: 0.1820\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 2s 76ms/step - loss: 0.8300 - accuracy: 0.6420 - val_loss: 2.0691 - val_accuracy: 0.1843\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.8132 - accuracy: 0.6670 - val_loss: 2.5663 - val_accuracy: 0.1933\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 2s 77ms/step - loss: 0.8726 - accuracy: 0.6340 - val_loss: 2.3625 - val_accuracy: 0.2045\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 2s 79ms/step - loss: 0.7771 - accuracy: 0.6876 - val_loss: 2.8443 - val_accuracy: 0.1978\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.7147 - accuracy: 0.7035 - val_loss: 2.2441 - val_accuracy: 0.2225\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.7573 - accuracy: 0.6899 - val_loss: 2.4136 - val_accuracy: 0.2539\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 2s 79ms/step - loss: 0.7261 - accuracy: 0.6853 - val_loss: 2.5364 - val_accuracy: 0.2382\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 2s 79ms/step - loss: 0.7188 - accuracy: 0.7206 - val_loss: 1.6018 - val_accuracy: 0.4404\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 2s 77ms/step - loss: 0.6146 - accuracy: 0.7263 - val_loss: 1.4588 - val_accuracy: 0.5079\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 2s 77ms/step - loss: 0.6795 - accuracy: 0.7457 - val_loss: 1.2978 - val_accuracy: 0.4607\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 2s 78ms/step - loss: 0.6836 - accuracy: 0.7229 - val_loss: 1.1514 - val_accuracy: 0.5393\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 2s 78ms/step - loss: 0.8443 - accuracy: 0.6534 - val_loss: 1.7171 - val_accuracy: 0.3663\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 2s 77ms/step - loss: 0.7186 - accuracy: 0.7047 - val_loss: 1.3943 - val_accuracy: 0.4854\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 2s 78ms/step - loss: 0.6653 - accuracy: 0.7127 - val_loss: 0.8877 - val_accuracy: 0.6652\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 2s 78ms/step - loss: 0.6091 - accuracy: 0.7571 - val_loss: 0.7405 - val_accuracy: 0.7101\n",
      "Epoch 26/50\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.6030 - accuracy: 0.7685"
     ]
    }
   ],
   "source": [
    "#fit the validation data to the model\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=50, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429675c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotmodelhistory(history): \n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5)) \n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(history.history['accuracy']) \n",
    "    axs[0].plot(history.history['val_accuracy']) \n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy') \n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    \n",
    "    axs[0].legend(['train', 'validate'], loc='upper left')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(history.history['loss']) \n",
    "    axs[1].plot(history.history['val_loss']) \n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss') \n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].legend(['train', 'validate'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "plotmodelhistory(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a7e10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = list(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaa447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "\n",
    "for batch_num in range(len(test_list)):\n",
    "    image_batch, label_batch = test_list[batch_num]\n",
    "    image_batch = image_batch.numpy()\n",
    "    label_batch = label_batch.numpy()\n",
    "    this_pred = model.predict_on_batch(image_batch)\n",
    "    this_classes = np.argmax(this_pred, axis=1)\n",
    "    \n",
    "    pred = tf.keras.utils.to_categorical(this_classes, num_classes=4)\n",
    "    \n",
    "    y_test_non_category = [ np.argmax(t) for t in label_batch ]\n",
    "    y_predict_non_category = [ np.argmax(t) for t in pred ]\n",
    "    \n",
    "    labels.extend(y_test_non_category)\n",
    "    preds.extend(y_predict_non_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64309caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = sorted(os.listdir(ham_dataset_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310848b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "conf_mat = confusion_matrix(labels, preds)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat, display_labels=label_names)\n",
    "disp.plot()\n",
    "plt.savefig('plots/cnn_da_ft_confmat_nv_' + str(nv_test_num) + '_gen_' + str(nv_gen_num) + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9378fa0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
