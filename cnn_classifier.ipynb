{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "80a1e582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bf84f839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "827de77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAE architecture and paramteres\n",
    "kernels = 2\n",
    "strides = 2\n",
    "latent_dim = 28\n",
    "filters = [32, 64, 128, 224, 512]\n",
    "input_shape = (224, 224, 3)\n",
    "last_conv_dim = int(input_shape[0] / (2 ** len(filters)))\n",
    "b_norm = 3\n",
    "#Batch Norm\n",
    "epsilon = 1e-5\n",
    "#spatial Classifier\n",
    "num_classes = 4\n",
    "#dataset\n",
    "ham_dataset_dir = 'ham_minified'\n",
    "batch_size = 48\n",
    "seed = 42\n",
    "#define early stopping paramter\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e1fa53c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_dataset_dir = 'ham_minified'\n",
    "nv_source_dir = 'nv_src'\n",
    "nv_test_num = 200\n",
    "nv_gen_num = 0\n",
    "batch_size = 48\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67ad329",
   "metadata": {},
   "source": [
    "### Combine True and Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "42f97d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = list(os.walk(ham_dataset_dir + '/nv'))[0][2]\n",
    "for image_to_delete in images:\n",
    "    path = Path(f'{ham_dataset_dir}/nv/{image_to_delete}')\n",
    "    path.unlink(missing_ok=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d4fa91ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = list(os.walk(nv_source_dir + '/nv_true'))[0][2]\n",
    "nv_images = random.sample(images, nv_test_num)\n",
    "for true_image in nv_images:\n",
    "    shutil.copy(nv_source_dir + '/nv_true/' + true_image, ham_dataset_dir + '/nv/' + true_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8e7f3abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = list(os.walk(nv_source_dir + '/gen_data'))[0][2]\n",
    "gen_images = random.sample(images, nv_gen_num)\n",
    "for gen_image in gen_images:\n",
    "    shutil.copy(nv_source_dir + '/gen_data/' + gen_image, ham_dataset_dir + '/nv/' + gen_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9cd9a9",
   "metadata": {},
   "source": [
    "### Data Processing & Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "891fbea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2926 files belonging to 4 classes.\n",
      "Using 877 files for validation.\n",
      "Found 2926 files belonging to 4 classes.\n",
      "Using 877 files for validation.\n"
     ]
    }
   ],
   "source": [
    "#load and split datatse\n",
    "train_ds = keras.preprocessing.image_dataset_from_directory(ham_dataset_dir, validation_split=0.3, color_mode='rgb',\n",
    "                                                          labels='inferred', label_mode='categorical', shuffle=True, subset='validation', image_size=(224, 224),\n",
    "                                                          batch_size=batch_size, seed=seed)\n",
    "\n",
    "val_ds = keras.preprocessing.image_dataset_from_directory(ham_dataset_dir, validation_split=0.3, color_mode='rgb',\n",
    "                                                          labels='inferred', label_mode='categorical', shuffle=True, subset='validation', image_size=(224, 224),\n",
    "                                                          batch_size=batch_size, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b251e51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2926 files belonging to 4 classes.\n",
      "Using 2049 files for training.\n"
     ]
    }
   ],
   "source": [
    "classes = train_ds.class_names\n",
    "train_ds_single_batch = keras.preprocessing.image_dataset_from_directory(ham_dataset_dir, validation_split=0.3, color_mode='rgb',\n",
    "                                                     labels='inferred', shuffle=True, subset='training', image_size=(224, 224),\n",
    "                                                     batch_size=1, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "06c83ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.40728022 0.66439689 0.65926641 3.73905109]\n"
     ]
    }
   ],
   "source": [
    "y = np.array([label.numpy()[0] for _, label in train_ds_single_batch])\n",
    "class_weights_list = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "print(class_weights_list)\n",
    "class_weights = {}\n",
    "\n",
    "for i in range(len(class_weights_list)):\n",
    "    class_weights[i] = class_weights_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7def4778",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batches = tf.data.experimental.cardinality(val_ds)\n",
    "test_ds = val_ds.take(val_batches // 2)\n",
    "val_ds = val_ds.skip(val_batches // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d63bf7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of validation batches: 10\n",
      "Number of test batches: 9\n"
     ]
    }
   ],
   "source": [
    "print('Number of validation batches: %d' % tf.data.experimental.cardinality(val_ds))\n",
    "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "27454626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale immages\n",
    "rescale = keras.layers.experimental.preprocessing.Rescaling(scale=1.0 / 255)\n",
    "train_ds = train_ds.map(lambda x, y: (rescale(x), y))\n",
    "val_ds = val_ds.map(lambda x, y: (rescale(x), y))\n",
    "test_ds = test_ds.map(lambda x, y: (rescale(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a700f5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#autotune dataset\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f955d0e",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "957ade24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_25 (Conv2D)          (None, 112, 112, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 112, 112, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_25 (Activation)  (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 56, 56, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 56, 56, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_26 (Activation)  (None, 56, 56, 64)        0         \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 28, 28, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_27 (Activation)  (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 14, 14, 224)       258272    \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 14, 14, 224)      896       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_28 (Activation)  (None, 14, 14, 224)       0         \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 7, 7, 512)         1032704   \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 7, 7, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_29 (Activation)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                1605696   \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,994,020\n",
      "Trainable params: 2,992,100\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#define the neural network\n",
    "model = Sequential()\n",
    "for conv_filter in filters:\n",
    "    model.add(keras.layers.Conv2D(conv_filter, 3, strides=2, padding='same', input_shape=input_shape))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-5), activation='relu'))\n",
    "model.add(keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#print summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "35adb275",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimize the model with using Adam\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655cd4b8",
   "metadata": {},
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea29581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19/19 [==============================] - 2s 85ms/step - loss: 3.0193 - accuracy: 0.3261 - val_loss: 1.5558 - val_accuracy: 0.1753\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 2s 77ms/step - loss: 1.2731 - accuracy: 0.4196 - val_loss: 1.7052 - val_accuracy: 0.1618\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 2s 77ms/step - loss: 1.0929 - accuracy: 0.5257 - val_loss: 1.8984 - val_accuracy: 0.1843\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 2s 77ms/step - loss: 1.0375 - accuracy: 0.5450 - val_loss: 2.1706 - val_accuracy: 0.1506\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 2s 78ms/step - loss: 0.9796 - accuracy: 0.5929 - val_loss: 2.5525 - val_accuracy: 0.1528\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.8904 - accuracy: 0.6192 - val_loss: 2.1513 - val_accuracy: 0.1528\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.8441 - accuracy: 0.6613 - val_loss: 2.4455 - val_accuracy: 0.1775\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 2s 82ms/step - loss: 0.8609 - accuracy: 0.6363 - val_loss: 2.3803 - val_accuracy: 0.1596\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.8369 - accuracy: 0.6385 - val_loss: 2.5389 - val_accuracy: 0.1798\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.8754 - accuracy: 0.6465 - val_loss: 3.8147 - val_accuracy: 0.1551\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.8542 - accuracy: 0.6385 - val_loss: 2.0196 - val_accuracy: 0.2292\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.6923 - accuracy: 0.7070 - val_loss: 3.2938 - val_accuracy: 0.2090\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.6493 - accuracy: 0.7172 - val_loss: 2.3494 - val_accuracy: 0.2382\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.6338 - accuracy: 0.7548 - val_loss: 4.0292 - val_accuracy: 0.1888\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.5848 - accuracy: 0.7537 - val_loss: 3.8455 - val_accuracy: 0.2360\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.5367 - accuracy: 0.7868 - val_loss: 3.5241 - val_accuracy: 0.2225\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.5710 - accuracy: 0.7651 - val_loss: 3.4308 - val_accuracy: 0.2000\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.5150 - accuracy: 0.7970 - val_loss: 3.1374 - val_accuracy: 0.3708\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 2s 82ms/step - loss: 0.4627 - accuracy: 0.8107 - val_loss: 2.9222 - val_accuracy: 0.3303\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 0.4168 - accuracy: 0.8449 - val_loss: 1.8221 - val_accuracy: 0.4270\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.3577 - accuracy: 0.8803 - val_loss: 1.7518 - val_accuracy: 0.4899\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.2874 - accuracy: 0.9156 - val_loss: 1.9930 - val_accuracy: 0.5079\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.2743 - accuracy: 0.9202 - val_loss: 1.2494 - val_accuracy: 0.5798\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.3307 - accuracy: 0.8826 - val_loss: 1.6939 - val_accuracy: 0.5303\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 0.3005 - accuracy: 0.9088 - val_loss: 1.0207 - val_accuracy: 0.6517\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 2s 85ms/step - loss: 0.3702 - accuracy: 0.8700 - val_loss: 2.6537 - val_accuracy: 0.4607\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 2s 78ms/step - loss: 0.3636 - accuracy: 0.8689 - val_loss: 0.7178 - val_accuracy: 0.7326\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 2s 78ms/step - loss: 0.4710 - accuracy: 0.8267 - val_loss: 1.0665 - val_accuracy: 0.6831\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 2s 78ms/step - loss: 0.6995 - accuracy: 0.7218 - val_loss: 0.7568 - val_accuracy: 0.7034\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 2s 77ms/step - loss: 0.4386 - accuracy: 0.8312 - val_loss: 1.6736 - val_accuracy: 0.5730\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 2s 78ms/step - loss: 0.3085 - accuracy: 0.9042 - val_loss: 1.1381 - val_accuracy: 0.7281\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 2s 78ms/step - loss: 0.2573 - accuracy: 0.9304 - val_loss: 0.6303 - val_accuracy: 0.7753\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 2s 78ms/step - loss: 0.2067 - accuracy: 0.9373 - val_loss: 0.4148 - val_accuracy: 0.8764\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 2s 77ms/step - loss: 0.1891 - accuracy: 0.9590 - val_loss: 0.2211 - val_accuracy: 0.9596\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 2s 78ms/step - loss: 0.1894 - accuracy: 0.9590 - val_loss: 0.7046 - val_accuracy: 0.8000\n",
      "Epoch 36/50\n",
      "19/19 [==============================] - 2s 78ms/step - loss: 0.1560 - accuracy: 0.9704 - val_loss: 0.3095 - val_accuracy: 0.9079\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 2s 79ms/step - loss: 0.1335 - accuracy: 0.9818 - val_loss: 0.1384 - val_accuracy: 0.9955\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 2s 79ms/step - loss: 0.1068 - accuracy: 0.9966 - val_loss: 0.2284 - val_accuracy: 0.9438\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 2s 78ms/step - loss: 0.0928 - accuracy: 0.9943 - val_loss: 0.2183 - val_accuracy: 0.9506\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 2s 78ms/step - loss: 0.0916 - accuracy: 0.9966 - val_loss: 0.1850 - val_accuracy: 0.9618\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 2s 79ms/step - loss: 0.0899 - accuracy: 0.9954 - val_loss: 0.2002 - val_accuracy: 0.9506\n",
      "Epoch 42/50\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.1062 - accuracy: 0.9861"
     ]
    }
   ],
   "source": [
    "#fit the validation data to the model\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=50, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb5c7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotmodelhistory(history): \n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5)) \n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(history.history['accuracy']) \n",
    "    axs[0].plot(history.history['val_accuracy']) \n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy') \n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    \n",
    "    axs[0].legend(['train', 'validate'], loc='upper left')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(history.history['loss']) \n",
    "    axs[1].plot(history.history['val_loss']) \n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss') \n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].legend(['train', 'validate'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "plotmodelhistory(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8fab0a",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a35b806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = list(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cb0153a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "\n",
    "for batch_num in range(len(test_list)):\n",
    "    image_batch, label_batch = test_list[batch_num]\n",
    "    image_batch = image_batch.numpy()\n",
    "    label_batch = label_batch.numpy()\n",
    "    this_pred = model.predict_on_batch(image_batch)\n",
    "    this_classes = np.argmax(this_pred, axis=1)\n",
    "    \n",
    "    pred = tf.keras.utils.to_categorical(this_classes, num_classes=4)\n",
    "    \n",
    "    y_test_non_category = [ np.argmax(t) for t in label_batch ]\n",
    "    y_predict_non_category = [ np.argmax(t) for t in pred ]\n",
    "    \n",
    "    labels.extend(y_test_non_category)\n",
    "    preds.extend(y_predict_non_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3f87bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = sorted(os.listdir(ham_dataset_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bbe9cf96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "conf_mat = confusion_matrix(labels, preds)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat, display_labels=label_names)\n",
    "disp.plot()\n",
    "plt.savefig('plots/cnn_da_ft_confmat_nv_' + str(nv_test_num) + '_gen_' + str(nv_gen_num) + '.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1677ea6",
   "metadata": {},
   "source": [
    "### Precision Recall Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9d31b0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "45ac3c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.84\n",
      "\n",
      "Micro Precision: 0.84\n",
      "Micro Recall: 0.84\n",
      "Micro F1-score: 0.84\n",
      "\n",
      "Macro Precision: 0.86\n",
      "Macro Recall: 0.88\n",
      "Macro F1-score: 0.87\n",
      "\n",
      "Weighted Precision: 0.84\n",
      "Weighted Recall: 0.84\n",
      "Weighted F1-score: 0.84\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bcc       0.92      0.93      0.92        82\n",
      "         bkl       0.78      0.79      0.78       152\n",
      "         mel       0.85      0.82      0.83       168\n",
      "          nv       0.91      0.97      0.94        30\n",
      "\n",
      "    accuracy                           0.84       432\n",
      "   macro avg       0.86      0.88      0.87       432\n",
      "weighted avg       0.84      0.84      0.84       432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(labels, preds)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(labels, preds, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(labels, preds, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(labels, preds, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(labels, preds, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(labels, preds, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(labels, preds, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(labels, preds, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(labels, preds, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(labels, preds, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(labels, preds, target_names=label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8fe4d3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dict = classification_report(labels, preds, target_names=label_names, output_dict=True)\n",
    "report_data = pd.DataFrame(report_dict)\n",
    "report_data.to_csv('reports/cnn_da_ft_report_nv_'+ str(nv_test_num) + '_gen_' + str(nv_gen_num) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d24909bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = pd.read_csv('reports/cnn_da_ft_report_nv_'+ str(nv_test_num) + '_gen_' + str(nv_gen_num) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1afb7b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Unnamed: 0        bcc         bkl         mel         nv  accuracy  \\\n",
      "0  precision   0.915663    0.779221    0.846626   0.906250  0.840278   \n",
      "1     recall   0.926829    0.789474    0.821429   0.966667  0.840278   \n",
      "2   f1-score   0.921212    0.784314    0.833837   0.935484  0.840278   \n",
      "3    support  82.000000  152.000000  168.000000  30.000000  0.840278   \n",
      "\n",
      "    macro avg  weighted avg  \n",
      "0    0.861940      0.840154  \n",
      "1    0.876100      0.840278  \n",
      "2    0.868712      0.840056  \n",
      "3  432.000000    432.000000  \n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
